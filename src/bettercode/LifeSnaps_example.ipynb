{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5397a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "db_import_dir = Path('/Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9318b6f9",
   "metadata": {},
   "source": [
    "## Step 1: load mongobd data from bson\n",
    "\n",
    "There are three data files:\n",
    "\n",
    "- fitbit.bson\n",
    "- sema.bson\n",
    "- surveys.bson\n",
    "\n",
    "we load these into the local mongodb using mongorestore.\n",
    "\n",
    "the id/user_id entry in the mongo records refers to the subject id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "342e7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_type_counts(db, collection_name, sample_size=3):\n",
    "    # Get distinct types in a collection and sample documents for each type\n",
    "    collection = db[collection_name]\n",
    "    distinct_types = collection.distinct(\"type\")\n",
    "    type_counts = {}\n",
    "    for dtype in distinct_types:\n",
    "        count = collection.count_documents({\"type\": dtype})\n",
    "        sample_docs = list(collection.find({\"type\": dtype}).limit(sample_size))\n",
    "        type_counts[dtype] = count\n",
    "        \n",
    "    return type_counts\n",
    "\n",
    "def get_collection_size(db, collection_name):\n",
    "    # Get the numner of documents in a collection\n",
    "\n",
    "    return db[collection_name].count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c55e4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'fitbit' has 0 documents, expected 71284346. Importing data...\n",
      "Importing data into collection 'fitbit' from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/fitbit.bson...\n",
      "Running command: mongorestore --host localhost --port 27017 --db lifesnaps --collection fitbit --drop /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/fitbit.bson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16T20:53:00.855-0800\tchecking for collection data in /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/fitbit.bson\n",
      "2025-12-16T20:53:00.856-0800\treading metadata for lifesnaps.fitbit from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/fitbit.metadata.json\n",
      "2025-12-16T20:53:00.889-0800\trestoring lifesnaps.fitbit from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/fitbit.bson\n",
      "2025-12-16T20:53:03.854-0800\t[........................]  lifesnaps.fitbit  246MB/9.02GB  (2.7%)\n",
      "2025-12-16T20:53:06.854-0800\t[#.......................]  lifesnaps.fitbit  511MB/9.02GB  (5.5%)\n",
      "2025-12-16T20:53:09.854-0800\t[#.......................]  lifesnaps.fitbit  758MB/9.02GB  (8.2%)\n",
      "2025-12-16T20:53:12.854-0800\t[##......................]  lifesnaps.fitbit  968MB/9.02GB  (10.5%)\n",
      "2025-12-16T20:53:15.854-0800\t[###.....................]  lifesnaps.fitbit  1.19GB/9.02GB  (13.2%)\n",
      "2025-12-16T20:53:18.854-0800\t[###.....................]  lifesnaps.fitbit  1.45GB/9.02GB  (16.0%)\n",
      "2025-12-16T20:53:21.854-0800\t[####....................]  lifesnaps.fitbit  1.66GB/9.02GB  (18.4%)\n",
      "2025-12-16T20:53:24.854-0800\t[#####...................]  lifesnaps.fitbit  1.90GB/9.02GB  (21.0%)\n",
      "2025-12-16T20:53:27.854-0800\t[#####...................]  lifesnaps.fitbit  2.15GB/9.02GB  (23.8%)\n",
      "2025-12-16T20:53:30.854-0800\t[######..................]  lifesnaps.fitbit  2.40GB/9.02GB  (26.7%)\n",
      "2025-12-16T20:53:33.854-0800\t[#######.................]  lifesnaps.fitbit  2.66GB/9.02GB  (29.5%)\n",
      "2025-12-16T20:53:36.854-0800\t[#######.................]  lifesnaps.fitbit  2.91GB/9.02GB  (32.3%)\n",
      "2025-12-16T20:53:39.854-0800\t[########................]  lifesnaps.fitbit  3.13GB/9.02GB  (34.7%)\n",
      "2025-12-16T20:53:42.854-0800\t[#########...............]  lifesnaps.fitbit  3.39GB/9.02GB  (37.6%)\n",
      "2025-12-16T20:53:45.854-0800\t[#########...............]  lifesnaps.fitbit  3.64GB/9.02GB  (40.4%)\n",
      "2025-12-16T20:53:48.854-0800\t[##########..............]  lifesnaps.fitbit  3.89GB/9.02GB  (43.1%)\n",
      "2025-12-16T20:53:51.854-0800\t[##########..............]  lifesnaps.fitbit  4.13GB/9.02GB  (45.8%)\n",
      "2025-12-16T20:53:54.854-0800\t[###########.............]  lifesnaps.fitbit  4.34GB/9.02GB  (48.1%)\n",
      "2025-12-16T20:53:57.854-0800\t[############............]  lifesnaps.fitbit  4.59GB/9.02GB  (50.9%)\n",
      "2025-12-16T20:54:00.854-0800\t[############............]  lifesnaps.fitbit  4.84GB/9.02GB  (53.7%)\n",
      "2025-12-16T20:54:03.854-0800\t[#############...........]  lifesnaps.fitbit  5.10GB/9.02GB  (56.6%)\n",
      "2025-12-16T20:54:06.854-0800\t[##############..........]  lifesnaps.fitbit  5.36GB/9.02GB  (59.4%)\n",
      "2025-12-16T20:54:09.854-0800\t[##############..........]  lifesnaps.fitbit  5.62GB/9.02GB  (62.3%)\n",
      "2025-12-16T20:54:12.854-0800\t[###############.........]  lifesnaps.fitbit  5.83GB/9.02GB  (64.6%)\n",
      "2025-12-16T20:54:15.854-0800\t[################........]  lifesnaps.fitbit  6.06GB/9.02GB  (67.2%)\n",
      "2025-12-16T20:54:18.854-0800\t[################........]  lifesnaps.fitbit  6.31GB/9.02GB  (69.9%)\n",
      "2025-12-16T20:54:21.854-0800\t[#################.......]  lifesnaps.fitbit  6.57GB/9.02GB  (72.8%)\n",
      "2025-12-16T20:54:24.854-0800\t[##################......]  lifesnaps.fitbit  6.81GB/9.02GB  (75.5%)\n",
      "2025-12-16T20:54:27.854-0800\t[##################......]  lifesnaps.fitbit  7.05GB/9.02GB  (78.2%)\n",
      "2025-12-16T20:54:30.854-0800\t[###################.....]  lifesnaps.fitbit  7.29GB/9.02GB  (80.8%)\n",
      "2025-12-16T20:54:33.854-0800\t[####################....]  lifesnaps.fitbit  7.55GB/9.02GB  (83.7%)\n",
      "2025-12-16T20:54:36.854-0800\t[####################....]  lifesnaps.fitbit  7.81GB/9.02GB  (86.6%)\n",
      "2025-12-16T20:54:39.854-0800\t[#####################...]  lifesnaps.fitbit  8.06GB/9.02GB  (89.4%)\n",
      "2025-12-16T20:54:42.854-0800\t[######################..]  lifesnaps.fitbit  8.31GB/9.02GB  (92.2%)\n",
      "2025-12-16T20:54:45.855-0800\t[######################..]  lifesnaps.fitbit  8.54GB/9.02GB  (94.7%)\n",
      "2025-12-16T20:54:48.855-0800\t[#######################.]  lifesnaps.fitbit  8.78GB/9.02GB  (97.4%)\n",
      "2025-12-16T20:54:51.722-0800\t[########################]  lifesnaps.fitbit  9.02GB/9.02GB  (100.0%)\n",
      "2025-12-16T20:54:51.722-0800\tfinished restoring lifesnaps.fitbit (71284346 documents, 0 failures)\n",
      "2025-12-16T20:54:51.722-0800\trestoring indexes for collection lifesnaps.fitbit from metadata\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"type_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"type\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"id_1_type_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"id\", Value:1}, primitive.E{Key:\"type\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"id_1_type_1_data.dateTime_1_data.value.bpm_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"id\", Value:1}, primitive.E{Key:\"type\", Value:1}, primitive.E{Key:\"data.dateTime\", Value:1}, primitive.E{Key:\"data.value.bpm\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"data.dateTime_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"data.dateTime\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"data.reading_time_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"data.reading_time\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"data.sleep_start_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"data.sleep_start\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"data.startTime_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"data.startTime\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"id_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"id\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:54:51.722-0800\tindex: &idx.IndexDocument{Options:primitive.M{\"background\":true, \"name\":\"data.timestamp_1\", \"ns\":\"raisV3_anonymized.fitbit\", \"v\":2}, Key:primitive.D{primitive.E{Key:\"data.timestamp\", Value:1}}, PartialFilterExpression:primitive.D(nil)}\n",
      "2025-12-16T20:59:25.881-0800\t71284346 document(s) restored successfully. 0 document(s) failed to restore.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported collection 'fitbit' with 71284346 documents.\n",
      "Collection 'sema' has 0 documents, expected 15380. Importing data...\n",
      "Importing data into collection 'sema' from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/sema.bson...\n",
      "Running command: mongorestore --host localhost --port 27017 --db lifesnaps --collection sema --drop /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/sema.bson\n",
      "Successfully imported collection 'sema' with 15380 documents.\n",
      "Collection 'surveys' has 0 documents, expected 935. Importing data...\n",
      "Importing data into collection 'surveys' from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/surveys.bson...\n",
      "Running command: mongorestore --host localhost --port 27017 --db lifesnaps --collection surveys --drop /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/surveys.bson\n",
      "Successfully imported collection 'surveys' with 935 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-16T20:59:31.410-0800\tchecking for collection data in /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/sema.bson\n",
      "2025-12-16T20:59:31.411-0800\treading metadata for lifesnaps.sema from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/sema.metadata.json\n",
      "2025-12-16T20:59:31.442-0800\trestoring lifesnaps.sema from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/sema.bson\n",
      "2025-12-16T20:59:31.492-0800\tfinished restoring lifesnaps.sema (15380 documents, 0 failures)\n",
      "2025-12-16T20:59:31.492-0800\tno indexes to restore for collection lifesnaps.sema\n",
      "2025-12-16T20:59:31.492-0800\t15380 document(s) restored successfully. 0 document(s) failed to restore.\n",
      "2025-12-16T20:59:31.538-0800\tchecking for collection data in /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/surveys.bson\n",
      "2025-12-16T20:59:31.538-0800\treading metadata for lifesnaps.surveys from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/surveys.metadata.json\n",
      "2025-12-16T20:59:31.560-0800\trestoring lifesnaps.surveys from /Users/poldrack/data_unsynced/LifeSnaps/rais_anonymized/mongo_rais_anonymized/surveys.bson\n",
      "2025-12-16T20:59:31.604-0800\tfinished restoring lifesnaps.surveys (935 documents, 0 failures)\n",
      "2025-12-16T20:59:31.604-0800\tno indexes to restore for collection lifesnaps.surveys\n",
      "2025-12-16T20:59:31.604-0800\t935 document(s) restored successfully. 0 document(s) failed to restore.\n"
     ]
    }
   ],
   "source": [
    "# Connect to MongoDB\n",
    "def get_mongo_client(host='localhost', port=27017):\n",
    "    try:\n",
    "        client = pymongo.MongoClient(f\"mongodb://{host}:{port}/\")\n",
    "    except pymongo.errors.ConnectionError as e:\n",
    "        raise Exception(f\"Error connecting to MongoDB - have you set it up yet?: {e}\")\n",
    "    return client\n",
    "\n",
    "client = get_mongo_client()\n",
    "\n",
    "# load the database and import data if necessary\n",
    "db = client['lifesnaps']\n",
    "collection_lengths = {\n",
    "    'fitbit': 71284346,\n",
    "    'sema': 15380,\n",
    "    'surveys': 935\n",
    "}\n",
    "\n",
    "# in general we will need to overwrite to get the full dataset to begin with\n",
    "overwrite = True\n",
    "\n",
    "for collection_name, expected_length in collection_lengths.items():\n",
    "    actual_length = get_collection_size(db, collection_name)\n",
    "    # use ge since we will removing some objects below\n",
    "    if actual_length >= expected_length and not overwrite:\n",
    "        print(f\"Collection '{collection_name}' already loaded with {actual_length} documents.\")\n",
    "    else:\n",
    "        # import the data from the BSON file\n",
    "        print(f\"Collection '{collection_name}' has {actual_length} documents, expected {expected_length}. Importing data...\")\n",
    "        import_file = db_import_dir / f\"{collection_name}.bson\"\n",
    "        if not import_file.exists():\n",
    "            raise FileNotFoundError(f\"Import file {import_file} does not exist.\")\n",
    "        print(f\"Importing data into collection '{collection_name}' from {import_file}...\")\n",
    "        command = f\"mongorestore --host {client.address[0]} --port {client.address[1]} --db lifesnaps --collection {collection_name} --drop {import_file}\"\n",
    "        print(f\"Running command: {command}\")\n",
    "        os.system(command)\n",
    "        \n",
    "        actual_length = get_collection_size(db, collection_name)\n",
    "        assert actual_length >= expected_length, f\"After import, collection '{collection_name}' has {actual_length} documents, expected {expected_length}.\"\n",
    "        print(f\"Successfully imported collection '{collection_name}' with {actual_length} documents.\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0729c2ec",
   "metadata": {},
   "source": [
    "### Step 2: remove unnecessary entries from fitbit database\n",
    "\n",
    "The fitbit store is huge and we don't need many of the entries, so let's remove them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad6fcb",
   "metadata": {},
   "source": [
    "First pull Profile records into a separate object store since they are a different kind of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6bfae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 'fitbit_profile' collection with 69 documents.\n"
     ]
    }
   ],
   "source": [
    "# create a new table containing all documents from fitbit with type 'Profile'\n",
    "profile_collection = db['fitbit_profile']\n",
    "profile_collection.drop()  # drop existing collection if it exists\n",
    "fitbit_collection = db['fitbit']\n",
    "profiles = list(fitbit_collection.find({\"type\": \"Profile\"}))\n",
    "if len(profiles) > 0:\n",
    "    profile_collection.insert_many(profiles)\n",
    "    print(f\"Created 'fitbit_profile' collection with {get_collection_size(db, 'fitbit_profile')} documents.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653da8c",
   "metadata": {},
   "source": [
    "Remove unwanted fitbit data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dd2b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 9845042 unwanted documents from 'fitbit' collection.\n",
      "Remaining documents in 'fitbit' collection: 61439304\n",
      "Final document counts in 'fitbit' collection after cleanup:\n",
      "Type: calories, Count: 9675782\n",
      "Type: heart_rate, Count: 48720040\n",
      "Type: lightly_active_minutes, Count: 7203\n",
      "Type: moderately_active_minutes, Count: 7203\n",
      "Type: sedentary_minutes, Count: 7203\n",
      "Type: sleep, Count: 4141\n",
      "Type: steps, Count: 3010529\n",
      "Type: very_active_minutes, Count: 7203\n"
     ]
    }
   ],
   "source": [
    "fitbit_types_to_keep = [\n",
    "    \"heart_rate\",\n",
    "    \"sleep\",\n",
    "    \"steps\",\n",
    "    \"lightly_active_minutes\",\n",
    "    \"moderately_active_minutes\",\n",
    "    \"very_active_minutes\",\n",
    "    \"sedentary_minutes\",\n",
    "    \"calories\",\n",
    "]\n",
    "\n",
    "# remove unwanted fitbit data\n",
    "fitbit_collection = db['fitbit']\n",
    "deletion_result = fitbit_collection.delete_many({\"type\": {\"$nin\": fitbit_types_to_keep}})\n",
    "print(f\"Removed {deletion_result.deleted_count} unwanted documents from 'fitbit' collection.\")\n",
    "print(f\"Remaining documents in 'fitbit' collection: {get_collection_size(db, 'fitbit')}\")\n",
    "print(\"Final document counts in 'fitbit' collection after cleanup:\")\n",
    "final_type_counts = get_collection_type_counts(db, 'fitbit')\n",
    "for dtype, count in final_type_counts.items():\n",
    "    print(f\"Type: {dtype}, Count: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d90f7",
   "metadata": {},
   "source": [
    "## Harmonize the documents and combine into a single database\n",
    "\n",
    "We want to be able to treat each of the different data types similarly, but currently some of them have their value in a different location than the `value` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3752b2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2 documents with null 'data.SURVEY_NAME' from 'sema' collection.\n",
      "Remaining documents in 'sema' collection: 15378\n",
      "Updated 15378 documents in 'sema' collection to add 'type' field.\n",
      "Document counts in 'sema' collection after adding 'type' field:\n",
      "Type: Context and Mood Survey, Count: 11526\n",
      "Type: Step Goal Survey, Count: 3852\n"
     ]
    }
   ],
   "source": [
    "# for sema collection, create a 'type' field based on data['SURVEY_NAME']\n",
    "\n",
    "sema_collection = db['sema']\n",
    "# first remove documents that None for data.SURVEY_NAME\n",
    "deletion_result = sema_collection.delete_many({\"data.SURVEY_NAME\": None})\n",
    "print(f\"Removed {deletion_result.deleted_count} documents with null 'data.SURVEY_NAME' from 'sema' collection.\")\n",
    "print(f\"Remaining documents in 'sema' collection: {get_collection_size(db,'sema')}\")\n",
    "# now update documents to add 'type'\n",
    "update_result = sema_collection.update_many(\n",
    "    {\"type\": {\"$exists\": False}},\n",
    "    [{\"$set\": {\"type\": \"$data.SURVEY_NAME\"}}]\n",
    ")\n",
    "print(f\"Updated {update_result.modified_count} documents in 'sema' collection to add 'type' field.\")\n",
    "print(f\"Document counts in 'sema' collection after adding 'type' field:\")\n",
    "sema_type_counts = get_collection_type_counts(db, 'sema')\n",
    "for dtype, count in sema_type_counts.items():\n",
    "    print(f\"Type: {dtype}, Count: {count}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb0057c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 'sema' collection into 'fitbit'. New 'fitbit' collection size: 61450830 documents.\n"
     ]
    }
   ],
   "source": [
    "# combine the sema collection into fitbit\n",
    "\n",
    "sema_collection = db['sema']\n",
    "# drop the \"Step Goal Survey\" from sema\n",
    "sema_collection.delete_many({\"type\": \"Step Goal Survey\"})\n",
    "\n",
    "fitbit_collection = db['fitbit']\n",
    "fitbit_collection.insert_many(sema_collection.find())\n",
    "print(f\"Combined 'sema' collection into 'fitbit'. New 'fitbit' collection size: {get_collection_size(db, 'fitbit')} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853eb7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 48720040 documents of type 'heart_rate' to add 'value' field from 'data.value.bpm'.\n",
      "Updated 4141 documents of type 'sleep' to add 'date' field from 'data.endTime'.\n",
      "Updated 4141 documents of type 'sleep' to add 'value' field from 'data.minutesAsleep'.\n",
      "Updated 7203 documents of type 'lightly_active_minutes' to add 'value' field from 'data.value'.\n",
      "Updated 7203 documents of type 'moderately_active_minutes' to add 'value' field from 'data.value'.\n",
      "Updated 7203 documents of type 'very_active_minutes' to add 'value' field from 'data.value'.\n",
      "Updated 7203 documents of type 'sedentary_minutes' to add 'value' field from 'data.value'.\n",
      "Updated 9675782 documents of type 'calories' to add 'date' field from 'data.dateTime'.\n",
      "Updated 9675782 documents of type 'calories' to add 'value' field from 'data.value'.\n",
      "Updated 3010529 documents of type 'steps' to add 'date' field from 'data.dateTime'.\n",
      "Updated 3010529 documents of type 'steps' to add 'value' field from 'data.value'.\n",
      "Updated 11526 documents of type 'Context and Mood Survey' to add 'date' field from 'data.COMPLETED_TS'.\n",
      "Updated 11526 documents of type 'Context and Mood Survey' to add 'value' field from 'data.MOOD'.\n",
      "\n",
      "Verifying updates:\n",
      "Type 'heart_rate': 48720040/48720040 documents now have 'value' field.\n",
      "Type 'sleep': 4141/4141 documents now have 'value' field.\n",
      "Type 'lightly_active_minutes': 7203/7203 documents now have 'value' field.\n",
      "Type 'moderately_active_minutes': 7203/7203 documents now have 'value' field.\n",
      "Type 'very_active_minutes': 7203/7203 documents now have 'value' field.\n",
      "Type 'sedentary_minutes': 7203/7203 documents now have 'value' field.\n",
      "Type 'calories': 9675782/9675782 documents now have 'value' field.\n",
      "Type 'steps': 3010529/3010529 documents now have 'value' field.\n",
      "Type 'Context and Mood Survey': 11526/11526 documents now have 'value' field.\n"
     ]
    }
   ],
   "source": [
    "# some already are called \"value\": calories, active/sedentary minutes\n",
    "value_variable = {\n",
    "    'heart_rate': 'value.bpm',\n",
    "    'sleep': 'minutesAsleep',\n",
    "    'lightly_active_minutes': 'value',\n",
    "    'moderately_active_minutes': 'value',\n",
    "    'very_active_minutes': 'value',\n",
    "    'sedentary_minutes': 'value',\n",
    "    'calories': 'value',\n",
    "    'steps': 'value',\n",
    "    \"Context and Mood Survey\": 'MOOD'\n",
    "}\n",
    "date_variable = {\n",
    "    'sleep': 'endTime',\n",
    "    'calories': 'dateTime',\n",
    "    'steps': 'dateTime',\n",
    "    \"Context and Mood Survey\": 'COMPLETED_TS'\n",
    "}\n",
    "# for each object that has type matching one of the keys in value_variable,\n",
    "# move data[value_variable] into 'value' field at root level of object\n",
    "\n",
    "fitbit_collection = db['fitbit']\n",
    "\n",
    "for doc_type, value_field in value_variable.items():\n",
    "    # Update documents of this type to move the value from data[value_field] to root level 'value'\n",
    "    update_result = fitbit_collection.update_many(\n",
    "        {\n",
    "            \"type\": doc_type,\n",
    "            f\"data.{value_field}\": {\"$exists\": True}\n",
    "        },\n",
    "        [\n",
    "            {\"$set\": {\n",
    "                \"value\": f\"$data.{value_field}\",\n",
    "                \"value_origin\": value_field\n",
    "            }}\n",
    "        ]\n",
    "    )\n",
    "    # fix date field if applicable\n",
    "    if doc_type in date_variable:\n",
    "        date_field = date_variable[doc_type]\n",
    "        date_update_result = fitbit_collection.update_many(\n",
    "            {\n",
    "                \"type\": doc_type,\n",
    "                f\"data.{date_field}\": {\"$exists\": True}\n",
    "            },\n",
    "            [\n",
    "                {\"$set\": {\n",
    "                    \"date\": f\"$data.{date_field}\",\n",
    "                    \"date_origin\": date_field\n",
    "                }}\n",
    "            ]\n",
    "        )\n",
    "        print(f\"Updated {date_update_result.modified_count} documents of type '{doc_type}' to add 'date' field from 'data.{date_field}'.\")\n",
    "    print(f\"Updated {update_result.modified_count} documents of type '{doc_type}' to add 'value' field from 'data.{value_field}'.\")\n",
    "\n",
    "print(\"\\nVerifying updates:\")\n",
    "for doc_type in value_variable.keys():\n",
    "    count_with_value = fitbit_collection.count_documents({\n",
    "        \"type\": doc_type,\n",
    "        \"value\": {\"$exists\": True}\n",
    "    })\n",
    "    total_count = fitbit_collection.count_documents({\"type\": doc_type})\n",
    "    print(f\"Type '{doc_type}': {count_with_value}/{total_count} documents now have 'value' field.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137d0f7",
   "metadata": {},
   "source": [
    "Harmonize by adding type field to sema database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a1d89",
   "metadata": {},
   "source": [
    "rename id to user_id for fitbit collection to harmonize with others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89b2a549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'id' field to 'user_id' in 61439304 documents in 'fitbit' collection.\n"
     ]
    }
   ],
   "source": [
    "# rename \"id\" field to \"user_id\" in fitbit collection\n",
    "\n",
    "# skip if all entities already have \"user_id\"\n",
    "if fitbit_collection.count_documents({\"user_id\": {\"$exists\": False}}) > 0:\n",
    "\n",
    "    rename_result = fitbit_collection.update_many(\n",
    "        {},\n",
    "        {\"$rename\": {\"id\": \"user_id\"}}\n",
    "    )\n",
    "    print(f\"Renamed 'id' field to 'user_id' in {rename_result.modified_count} documents in 'fitbit' collection.\")\n",
    "else:\n",
    "    print(\"Field 'id' already renamed to 'user_id' in 'fitbit' collection; skipping rename.\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df746117",
   "metadata": {},
   "source": [
    "Doublecheck that every document has a fields for type, value, user_id, and date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "523fa955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing field counts in 'fitbit' collection:\n",
      "Field 'user_id': 0 documents missing this field.\n",
      "Field 'type': 0 documents missing this field.\n",
      "Field 'value': 0 documents missing this field.\n",
      "Field 'date': 48748852 documents missing this field.\n"
     ]
    }
   ],
   "source": [
    "field_to_check_for = ['user_id', 'type', 'value', 'date']\n",
    "# check that all documents in fitbit collection have these fields\n",
    "missing_field_counts = {}\n",
    "for field in field_to_check_for:\n",
    "    count_missing = fitbit_collection.count_documents({field: {\"$exists\": False}})\n",
    "    missing_field_counts[field] = count_missing\n",
    "print(\"Missing field counts in 'fitbit' collection:\")\n",
    "for field, count in missing_field_counts.items():\n",
    "    print(f\"Field '{field}': {count} documents missing this field.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce192d95",
   "metadata": {},
   "source": [
    "### Combine all three stores into a single store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce02ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete intermediate collections if desired\n",
    "#fitbit_collection.drop()\n",
    "#sema_collection.drop()\n",
    "#print(\"Deleted intermediate collections 'fitbit' and 'sema'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e7e8199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of 'lifesnaps_data' collection: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# get total size of lifesnaps_data collection in gigabytes\n",
    "\n",
    "total_size_gb = get_collection_size(db, 'lifesnaps_data') / 1e7\n",
    "print(f\"Total size of 'lifesnaps_data' collection: {total_size_gb:.02f} GB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bettercode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
